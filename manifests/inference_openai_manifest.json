{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "manifest_version": "1.0",
  "project": "enterprise-ai",
  "module": "inference",
  "module_type": "inference_openai",
  "description": "OpenAI-compatible inference module for chat completions and embeddings",
  "metadata": {
    "created_at": "2024-01-15T10:00:00Z",
    "updated_at": "2024-01-15T10:00:00Z",
    "owner": "ml-platform-team",
    "tags": ["inference", "openai", "llm"]
  },
  "runtime": {
    "type": "python:3.11",
    "implementation": "src.modules.inference_openai.InferenceOpenAIModule",
    "dependencies": [
      "httpx>=0.25.0",
      "pydantic>=2.0.0"
    ],
    "resource_requirements": {
      "memory": "512Mi",
      "cpu": "500m",
      "gpu": false
    }
  },
  "endpoints": {
    "dev": {
      "primary": "http://dev-llm-gateway.internal:8080",
      "fallback": "http://dev-llm-backup.internal:8080"
    },
    "staging": {
      "primary": "http://staging-llm-gateway.internal:8080",
      "fallback": null
    },
    "prod": {
      "primary": "https://prod-llm-lb.internal",
      "fallback": "https://prod-llm-backup.internal"
    }
  },
  "configuration_references": [
    {
      "name": "api_key",
      "type": "secret",
      "source": "vault://secrets/inference/openai_api_key",
      "required": true
    },
    {
      "name": "jwt_signing_key",
      "type": "secret",
      "source": "vault://secrets/jwt/signing_key",
      "required": true
    },
    {
      "name": "model_mapping",
      "type": "config",
      "source": "configmap://inference/model_mappings",
      "required": true,
      "default": {
        "gpt-4": "gpt-4-1106-preview",
        "gpt-3.5-turbo": "gpt-3.5-turbo-1106"
      }
    },
    {
      "name": "rate_limits",
      "type": "config",
      "source": "configmap://inference/rate_limits",
      "required": false,
      "default": {
        "requests_per_minute": 60,
        "tokens_per_minute": 90000
      }
    },
    {
      "name": "rag_endpoint",
      "type": "config",
      "source": "service://rag/endpoint",
      "required": false
    }
  ],
  "api_schema": {
    "type": "openapi",
    "version": "3.0",
    "url": "https://schemas.internal/openai/v1/openapi.yaml",
    "validation": {
      "request": true,
      "response": false
    }
  },
  "routing": {
    "path_patterns": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/embeddings",
      "/v1/models"
    ],
    "method_allowlist": ["GET", "POST"],
    "authentication": {
      "required": true,
      "types": ["bearer", "api_key"],
      "jwt_validation": {
        "enabled": true,
        "service": "dsp_ai_jwt",
        "claims_required": ["sub", "exp", "scope"]
      }
    }
  },
  "observability": {
    "logging": {
      "level": "INFO",
      "format": "json",
      "sensitive_fields": ["api_key", "authorization"]
    },
    "metrics": {
      "enabled": true,
      "prometheus_port": 9090,
      "custom_metrics": [
        "inference_requests_total",
        "inference_tokens_used",
        "inference_latency_seconds"
      ]
    },
    "tracing": {
      "enabled": true,
      "provider": "opentelemetry",
      "sampling_rate": 0.1
    }
  },
  "policies": {
    "retry": {
      "max_attempts": 3,
      "backoff": "exponential",
      "initial_delay_ms": 100
    },
    "timeout": {
      "request_timeout_seconds": 30,
      "stream_timeout_seconds": 300
    },
    "circuit_breaker": {
      "enabled": true,
      "failure_threshold": 5,
      "timeout_duration_seconds": 30
    }
  },
  "lifecycle": {
    "health_check": {
      "path": "/health",
      "interval_seconds": 30,
      "timeout_seconds": 5
    },
    "graceful_shutdown": {
      "timeout_seconds": 30,
      "drain_connections": true
    },
    "auto_scaling": {
      "enabled": true,
      "min_replicas": 2,
      "max_replicas": 10,
      "target_cpu_utilization": 70
    }
  }
}
